# Hand-Gesture-based-Sketching-to-Image-Translation



## Overview
This project explores the development of a system that translates hand gesture-based sketches into high-quality images using MediaPipe for gesture recognition and Stable Diffusion for image generation. The goal is to create an intuitive interface for artists and designers, where hand gestures are used as sketch commands and these sketches are transformed into detailed and realistic images through advanced AI models.

### Authors
S Abhishek (212221230002)
V NaveenKumar (212221230068)
S Dhanush Praboo (212221230019)
### Institution
Saveetha Engineering College, Thandalam, Chennai 602105.
Affiliated to Anna University - Chennai 600 025
### Supervisor
Mrs. S.Selvanayaki, M.Tech., Assistant Professor, Dept of Artificial Intelligence and Data Science
## Project Abstract
This project integrates MediaPipe for real-time hand gesture recognition and Stable Diffusion for image generation. The system captures hand gestures, interprets them as sketch commands on a digital canvas, and uses these sketches to generate detailed images. It leverages Python, TensorFlow/PyTorch, and OpenCV for implementation. The system is evaluated based on gesture recognition accuracy, image quality, and user feedback.
## Key Technologies
Python: The main programming language used for the project.
MediaPipe: Used for real-time hand gesture recognition.
Stable Diffusion: Used for generating high-quality images from sketches.
Streamlit: Used for building the user interface.
## System Components
Gesture Recognition Module: Uses MediaPipe to detect and track hand gestures in real-time.
Sketch Generation Interface: Maps hand gestures to sketching actions on a digital canvas.
Image Generation Module: Uses Stable Diffusion to convert sketches into high-quality images.
User Interface (UI): Developed with Streamlit to provide real-time feedback and visualization.
## Implementation Details
Gesture Recognition with MediaPipe: Detects 21 key points on the hand for real-time gesture tracking.
Sketch Generation: Translates hand gestures into sketches on a digital canvas.
Prompt Generation with Gemini: Creates AI-friendly textual prompts based on the sketch.
Sketch-to-Image Translation: Uses Stable Diffusion to transform sketches into refined images.
Visualization with Streamlit: Provides an interactive user interface for live feedback and display.
## Advantages of the Proposed System
Utilizes MediaPipe for accurate and fast gesture tracking.
Leverages Stable Diffusion to generate high-resolution, detailed images from sketches.
Provides an intuitive and accessible interface for users.
Ensures minimal processing delay for smooth interaction.
## Conclusion
The Hand Gesture-Based Sketching to Image Translation system combines real-time gesture recognition with advanced image generation techniques, providing an intuitive and accessible tool for digital art creation. Future enhancements could include multi-hand tracking, real-time feedback during sketching, and integration with augmented reality (AR).
## Output



## References
~~~
Jayesh S Sonkusare, et al., A review on hand gesture recognition system, 2015.
Bowen Zhang, et al., Styleswin: Transformer-based GAN for high-resolution image generation, 2022.
Yongyi Lu, et al., Image generation from sketch constraint using contextual GAN, 2018.
Cui, Y., et al., Real-time Hand Tracking with MediaPipe, 2019.
Zhang, Z., et al., Hand Gesture Recognition Using Deep Learning, 2021.
Ramesh, A., et al., DALL-E 2: Creating Images from Text, 2021.
Rombach, R., et al., Stable Diffusion: High-Resolution Image Synthesis with Latent Textual Diffusion Models, 2022.
Preece, J., et al., Human-Computer Interaction, 2015.
Norman, D. A., The Design of Everyday Things, 2013.
Ren, Z., et al., Real-time Hand Gesture Recognition for Human-Computer Interaction, 2017.
~~~






